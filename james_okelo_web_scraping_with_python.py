# -*- coding: utf-8 -*-
"""James Okelo: Web Scraping with Python

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tjpKKbbX7bv73u7X_8-MsxLrCbs-Rdof

<font color='#2F4F4F'>To use this notebook on Colaboratory, you will need to make a copy of it. Go to File > Save a Copy in Drive. You can then use the new copy that will appear in the new tab.</font>

# <font color='#2F4F4F'>AfterWork Data Science: Web Scraping with Python</font>

## <font color='#2F4F4F'>Prerequisites</font>
"""

# We first import the required libraries
# ---
#
import pandas as pd             # library for data manupation
import requests                 # library for fetching a web page 
from bs4 import BeautifulSoup   # library for extrating contents from a webpage

"""## <font color='#2F4F4F'>Step 1: Obtaining our Data</font>"""

# PigiaMe: https://www.pigiame.co.ke/it-software-jobs
# ---
#
pigia_me = requests.get('https://www.pigiame.co.ke/it-software-jobs')
pigia_me

# MyJobMag: https://www.myjobmag.co.ke/jobs-by-field/information-technology
# ---
#
MyJobMag = requests.get('https://www.myjobmag.co.ke/jobs-by-field/information-technology')
MyJobMag

# KenyanJob: https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133
# ---
#
KenyanJob = requests.get('https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133')
KenyanJob

"""## <font color='#2F4F4F'>Step 2: Parsing</font>"""

# Parsing our document: pigia_me
# ---
# 
soup_pigiame = BeautifulSoup(pigia_me.text, "html.parser")

# Parsing our document: my_job_mag
# ---
#  
soup_myjobmag = BeautifulSoup(MyJobMag.text, "html.parser")

# Parsing our document: kenyan_job
# ---
# 
soup_kjob = BeautifulSoup(KenyanJob.text, "html.parser")

"""## <font color='#2F4F4F'>Step 3: Extracting Required Elements</font>"""

# 1. Extracting job titles and links: pigia me
# ---
# 
jobs = soup_pigiame.find_all("div", "listings-cards__list-item")

titles = []
links = []

for job in jobs:
  title = job.find('div', 'listing-card__header__title').get_text().strip()
  link =  job.a.get('href')
  titles.append(title)
  links.append(link)

# 2. Extracting job titles: my_job_mag
# ---
jobs_myjobmag = soup_myjobmag.find_all("li", "job-information")

titles_myjobmag = []
links_myjobmag = []

for job in jobs_myjobmag:
  title = job.h2.a.get_text().strip()
  link = 'https://www.myjobmag.co.ke/jobs-by-field/information-technology' + job.h2.a.get('href')
  titles_myjobmag.append(title)
  links_myjobmag.append(link)

# 3. Extracting job titles: kenya_job
# ---
jobs_kjob = soup_kjob.find_all('div', 'col-lg-5 col-md-5 col-sm-5 col-xs-12 job-title')

titles_kjob = []
links_kjob = []

for job in jobs_kjob:
  title = job.h5.a.get_text().strip()
  link = 'https://www.kenyajob.com/job-vacancies-search-kenya?f%5B0%5D=im_field_offre_secteur%3A133' + job.h5.a.get('href')
  titles_kjob.append(title)
  links_kjob.append(link)

"""## <font color='#2F4F4F'>Step 4: Saving our Data</font>"""

# Saving the scraped contents in a dataframe and preview our data
# ---
#
jobs_df = pd.DataFrame({"Title": (titles + titles_myjobmag + titles_kjob), "Link": (links + links_myjobmag + links_kjob)})
jobs_df.sample(10)